{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8718335,"sourceType":"datasetVersion","datasetId":5231022}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-18T08:00:38.223100Z","iopub.execute_input":"2024-06-18T08:00:38.223761Z","iopub.status.idle":"2024-06-18T08:00:38.236218Z","shell.execute_reply.started":"2024-06-18T08:00:38.223729Z","shell.execute_reply":"2024-06-18T08:00:38.235141Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"/kaggle/input/turkish/7allV03.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch \nimport pandas as pd\nfrom transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-18T08:00:38.238180Z","iopub.execute_input":"2024-06-18T08:00:38.238566Z","iopub.status.idle":"2024-06-18T08:00:38.245497Z","shell.execute_reply.started":"2024-06-18T08:00:38.238533Z","shell.execute_reply":"2024-06-18T08:00:38.244600Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"from torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-18T08:00:38.246872Z","iopub.execute_input":"2024-06-18T08:00:38.247263Z"},"trusted":true},"execution_count":null,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}},{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\n# Since we're in /kaggle/working, we specify the file name directly\nfile_path = '/kaggle/input/turkish/7allV03.csv'  # Assuming train-3.csv is directly in /kaggle/working\n\ntry:\n    # Use pandas to read the CSV file\n    df = pd.read_csv(file_path)\n    \n    # Display the first few rows of the dataframe to confirm it's loaded correctly\n    #print(df.head())\nexcept FileNotFoundError:\n    print(f\"The file {file_path} was not found in the current working directory.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = df['category'].unique().tolist()\nlabels = [s.strip() for s in labels]\nlabels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_LABELS = len(labels)\n\nid2label={id:label for id,label in enumerate(labels)}\n\nlabel2id={label:id for id,label in enumerate(labels)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label2id","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Strip is used to remove the extra space before or after the category label like example ' spor', 'spor ', 'spor' will make different sentence\ndf[\"labels\"]=df.category.map(lambda x: label2id[x.strip()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.category.value_counts().plot(kind='pie', figsize=(10,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained(\"dbmdz/bert-base-turkish-uncased\", max_length=512)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(\"dbmdz/bert-base-turkish-uncased\", num_labels=NUM_LABELS, id2label=id2label, label2id=label2id)\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE= df.shape[0]\n\ntrain_texts= list(df.text[:SIZE//2])\n\nval_texts=   list(df.text[SIZE//2:(3*SIZE)//4 ])\n\ntest_texts=  list(df.text[(3*SIZE)//4:])\n\ntrain_labels= list(df.labels[:SIZE//2])\n\nval_labels=   list(df.labels[SIZE//2:(3*SIZE)//4])\n\ntest_labels=  list(df.labels[(3*SIZE)//4:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_texts), len(val_texts), len(test_texts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings  = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataLoader(Dataset):\n    \"\"\"\n    Custom Dataset class for handling tokenized text data and corresponding labels.\n    Inherits from torch.utils.data.Dataset.\n    \"\"\"\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        # Retrieve tokenized data for the given index\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        # Add the label for the given index to the item dictionary\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_encodings, train_labels)\n\nval_dataloader = DataLoader(val_encodings, val_labels)\n\ntest_dataset = DataLoader(test_encodings, test_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    # Extract true labels from the input object\n    labels = pred.label_ids\n    \n    # Obtain predicted class labels by finding the column index with the maximum probability\n    preds = pred.predictions.argmax(-1)\n    \n    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n    \n    # Calculate the accuracy score using sklearn's accuracy_score function\n    acc = accuracy_score(labels, preds)\n\n    # Return the computed metrics as a dictionary\n    return {\n        'Accuracy': acc,\n        'F1': f1,\n        'Precision': precision,\n        'Recall': recall\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    # The output directory where the model predictions and checkpoints will be written\n    output_dir='./TTC4900Model', \n    do_train=True,\n    do_eval=True,\n    #  The number of epochs, defaults to 3.0 \n    num_train_epochs=100,              \n    per_device_train_batch_size=16,  \n    per_device_eval_batch_size=32,\n    # Number of steps used for a linear warmup\n    warmup_steps=100,                \n    weight_decay=0.01,\n    logging_strategy='steps',\n   # TensorBoard log directory                 \n    logging_dir='./multi-class-logs',            \n    logging_steps=50,\n    evaluation_strategy=\"steps\",\n    eval_steps=50,\n    save_strategy=\"steps\", \n    fp16=True,\n    load_best_model_at_end=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    # the pre-trained model that will be fine-tuned \n    model=model,\n     # training arguments that we defined above                        \n    args=training_args,                 \n    train_dataset=train_dataloader,         \n    eval_dataset=val_dataloader,            \n    compute_metrics= compute_metrics\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(text):\n    \"\"\"\n    Predicts the class label for a given input text\n\n    Args:\n        text (str): The input text for which the class label needs to be predicted.\n\n    Returns:\n        probs (torch.Tensor): Class probabilities for the input text.\n        pred_label_idx (torch.Tensor): The index of the predicted class label.\n        pred_label (str): The predicted class label.\n    \"\"\"\n    # Tokenize the input text and move tensors to the GPU if available\n    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n\n    # Get model output (logits)\n    outputs = model(**inputs)\n\n    probs = outputs[0].softmax(1)\n    \"\"\" Explanation outputs: The BERT model returns a tuple containing the output logits (and possibly other elements depending on the model configuration). In this case, the output logits are the first element in the tuple, which is why we access it using outputs[0].\n\n    outputs[0]: This is a tensor containing the raw output logits for each class. The shape of the tensor is (batch_size, num_classes) where batch_size is the number of input samples (in this case, 1, as we are predicting for a single input text) and num_classes is the number of target classes.\n\n    softmax(1): The softmax function is applied along dimension 1 (the class dimension) to convert the raw logits into class probabilities. Softmax normalizes the logits so that they sum to 1, making them interpretable as probabilities. \"\"\"\n\n    # Get the index of the class with the highest probability\n    # argmax() finds the index of the maximum value in the tensor along a specified dimension.\n    # By default, if no dimension is specified, it returns the index of the maximum value in the flattened tensor.\n    pred_label_idx = probs.argmax()\n\n    # Now map the predicted class index to the actual class label \n    # Since pred_label_idx is a tensor containing a single value (the predicted class index), \n    # the .item() method is used to extract the value as a scalar\n    pred_label = model.config.id2label[pred_label_idx.item()]\n\n    return probs, pred_label_idx, pred_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test with a an example text in Turkish\ntext = \"Makine öğrenimi kendisi de daha da otomatik hale doğru ilerliyor.\"\n# \"Machine Learning itself is moving towards more and more automated\"\npredict(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"turkish-text-classification-model\"\ntrainer.save_model(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"turkish-text-classification-model\"\n\n\nmodel = BertForSequenceClassification.from_pretrained(model_path)\ntokenizer= BertTokenizerFast.from_pretrained(model_path)\nnlp= pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp(\"Bugün hava çok güzel, dışarıda yürümek istiyorum.\")\n# Today the weather is very nice, I want to go for a walk outside\n\n# Gives below output\n#[{'label': 'saglik', 'score': 0.8295329213142395}]\n# \"Saglik\" is a Turkish word that means \"health\" in English.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp(\"Derin Öğrenme ve Yapay Zeka dünyayı değiştirecek.\")\n# Deep Learning and AI is going to change the world\n\n# gives below output\n#[{'label': 'teknoloji', 'score': 0.9932782053947449}]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp(\"Son zamanlarda ekonomideki oynaklık nedeniyle, borsa endeksi oldukça düşük seviyelerde seyrediyor.\")\n# Due to recent volatility in the economy, the stock market index has been at quite low levels\n\n#gives below output\n#[{'label': 'ekonomi', 'score': 0.9850727915763855}]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.youtube.com/watch?v=4nNbg4bWDrQ\n#reference video","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}